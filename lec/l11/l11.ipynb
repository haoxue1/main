{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CS579: Lecture 11  \n",
    "\n",
    "**Seniment Analysis II (Machine Learning)**\n",
    "\n",
    "*[Dr. Aron Culotta](http://cs.iit.edu/~culotta)*  \n",
    "*[Illinois Institute of Technology](http://iit.edu)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is machine learning?\n",
    "<br><br><br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is machine learning?\n",
    "\n",
    "- [Dietterich: \"Machine Learning\"](http://web.engr.oregonstate.edu/~tgd/publications/nature-ecs-machine-learning.pdf)\n",
    "- [Domingos: \"A few useful things to know about machine learning\"](http://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)\n",
    "<br><br><br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is machine learning?\n",
    "\n",
    "\"Study of methods for programming computers to learn.\" \n",
    "\n",
    "-- Dietterich\n",
    "\n",
    "<br><br><br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is machine learning?\n",
    "\n",
    "Study of systems that \"automatically learn programs from data\" \n",
    "\n",
    "-- Domingos\n",
    "\n",
    "<br><br><br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is machine learning?\n",
    "\n",
    "A problem-solving technique that solves future problem instances based on\n",
    "patterns found in past problem instances\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![spam](images/spam.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/search.png' width='50%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/netflix.png', width='70%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/bw.png' width='50%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/chopper.png' width='70%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/car.jpg' width='70%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![money](images/money.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/doc.png' width='40%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/siri.png' width='40%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/watson.png' width='70%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Notation\n",
    "\n",
    "- $\\vec{x} \\in \\mathcal{X}$ &nbsp;&nbsp;&nbsp;&nbsp; *instance*, *example*, *input*\n",
    "  - e.g., an email\n",
    "- $y \\in \\mathcal{Y}$ &nbsp;&nbsp;&nbsp;&nbsp; *target*, *class*, *label*, *output*\n",
    "  - e.g., $y=1$: spam ; $y=0$: not spam\n",
    "- $f: \\mathcal{X} \\mapsto \\mathcal{Y}$ &nbsp;&nbsp;&nbsp;&nbsp; *hypothesis*, *learner*, *model*, *classifier*\n",
    "  - e.g., if $x$ contain the word *free*, $y$ is $1$.\n",
    "  \n",
    "  <br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem types\n",
    "\n",
    "- **Classification**\n",
    "  - $\\vec{x}$: image of a person ;  $y$: gender\n",
    "- **Regression**\n",
    "  - $\\vec{x}$: image of a person ; $y$: age\n",
    "- **Clustering**\n",
    "  - $\\vec{x}$: images of people ; $y$: cluster id of people that look similar\n",
    "- **Structured classification**\n",
    "  - $\\vec{x}$: image of a person ; $\\vec{y}$: location of their eyes and ears\n",
    "  - $X$: sequence of images of people ; $Y$: subsequences containing people running\n",
    "  \n",
    "  <br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Workflow\n",
    "\n",
    "1. **Collect** raw data: emails\n",
    "2. Manually **categorize** them:  spam or not\n",
    "3. **Vectorize**: email -> word counts [**features**]\n",
    "4. **Train** / **Fit**: create $f(x)$\n",
    "5. **Collect** new raw data\n",
    "6. **Predict**: compute $f(x)$ for new $x$\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Spam Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Steps 1 & 2: Collect and categorize**\n",
    "\n",
    "**Spam:**\n",
    "\n",
    "> Free credit report!\n",
    "\n",
    "\n",
    "> Free money!\n",
    "\n",
    "\n",
    "**Not spam:**\n",
    "\n",
    "> Are you free tonight?\n",
    "\n",
    "> How are you?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Step 3: Vectorize**\n",
    "\n",
    "> 'Free money!'\n",
    "\n",
    "becomes\n",
    "\n",
    "```\n",
    "free: 1\n",
    "money: 1\n",
    "!: 1\n",
    "?: 0\n",
    "credit: 0\n",
    "...\n",
    "```\n",
    "\n",
    "**Representation**: \"Feature engineering is the key\" -- Domingos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Step 4: Train/Fit**\n",
    "\n",
    "Which model to use?\n",
    "\n",
    "- Naive Bayes\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- K-Nearest Neighbors\n",
    "- Support Vector Machines\n",
    "- ... many many more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Steps 5-6: Predict on new data**\n",
    "\n",
    "> Free vacation!\n",
    "\n",
    "**Spam**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do you know if it works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# X: each row is a feature vector for one document.\n",
    "X = [(0, 0),\n",
    "     (1, 0),\n",
    "     (0,3),\n",
    "     (1,3)]\n",
    "# y: element i is a label for ith document\n",
    "y = [0, 0, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEPCAYAAABCyrPIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119592a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the data. \n",
    "# Red means class 0, blue means class 1.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_data(X, y):\n",
    "    \"\"\" Assumes 2-d data. \"\"\"\n",
    "    plt.figure()\n",
    "    for xi, yi in zip(X, y):\n",
    "        color = 'r' if yi == 0 else 'b'\n",
    "        plt.plot(xi[0], xi[1], color + 'o', ms=20)\n",
    "    plt.xlabel('feature 0')\n",
    "    plt.ylabel('feature 1')\n",
    "    plt.xlim((-1,2))\n",
    "    plt.ylim((-1, 4))\n",
    "    plt.annotate('class 0', xy=(1.2, 0), color='r', size=15)\n",
    "    plt.annotate('class 1', xy=(1.2, 3), color='b', size=15)\n",
    "    plt.show()\n",
    "    \n",
    "plot_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Simplest machine learning algorithm:\n",
    "\n",
    "class SimplestMachine:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.f = dict()\n",
    "\n",
    "    def train(self, X, y):\n",
    "        for xi, yi in zip(X, y):\n",
    "          self.f[xi] = yi\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.f[x]\n",
    "\n",
    "# What does this do?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'a'), (2, 'b'), (3, 'c')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does zip do?\n",
    "zip([1, 2, 3], ['a', 'b', 'c', 'd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred\ttruth\n",
      "0\t0\n",
      "0\t0\n",
      "1\t1\n",
      "1\t1\n"
     ]
    }
   ],
   "source": [
    "simplest_machine = SimplestMachine()\n",
    "simplest_machine.train(X, y)\n",
    "predictions = [simplest_machine.predict(xi) for xi in X]\n",
    "print 'pred\\ttruth\\n', '\\n'.join('%d\\t%d' % (p, yi) for p, yi in zip(predictions, y))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(0, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-0c4f7675ee59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# What does it do for unseen example?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msimplest_machine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-877c09f05652>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# What does this do?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0, 4)"
     ]
    }
   ],
   "source": [
    "# What does it do for unseen example?\n",
    "simplest_machine.predict((0, 4))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Second simplest machine learning algorithm:\n",
    "import numpy as np\n",
    "\n",
    "class SimpleMachine:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.f = dict()\n",
    "\n",
    "    def train(self, X, y):\n",
    "        for xi, yi in zip(X, y):\n",
    "          self.f[xi] = yi\n",
    "\n",
    "    def predict(self, x):\n",
    "        x_closest = self.find_most_similar(x)\n",
    "        return self.f[x_closest]\n",
    "    \n",
    "    def find_most_similar(self, x):\n",
    "        best_idx = np.argmin([self.distance(x, xi)\n",
    "                              for xi in self.f.keys()])\n",
    "        return self.f.keys()[best_idx]\n",
    "\n",
    "    def distance(self, x, xi):\n",
    "        return np.sqrt(np.sum((np.array(x)-np.array(xi))**2))\n",
    "        \n",
    "# What does this do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred\ttruth\n",
      "0\t0\n",
      "0\t0\n",
      "1\t1\n",
      "1\t1\n"
     ]
    }
   ],
   "source": [
    "simple_machine = SimpleMachine()\n",
    "simple_machine.train(X, y)\n",
    "predictions = [simple_machine.predict(xi) for xi in X]\n",
    "print 'pred\\ttruth\\n', '\\n'.join('%d\\t%d' % (p, yi) for p, yi in zip(predictions, y))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does it do for unseen example?\n",
    "simple_machine.predict((0, 4))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/knn.png' width='80%'/>\n",
    "\n",
    "<http://www.scholarpedia.org/article/K-nearest_neighbor>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Generalization\n",
    "\n",
    "How accurate will I be on a new, unobserved example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do you know if it works?\n",
    "\n",
    "1. Train on data ${\\mathcal D_1}$\n",
    "2. Predict on data ${\\mathcal D_2}$\n",
    "3. Compute accuracy on ${\\mathcal D_2}$.\n",
    "   - Why not ${\\mathcal D_1}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do you know if it works?\n",
    "\n",
    "1. Train on data ${\\mathcal D_1}$\n",
    "2. Predict on data ${\\mathcal D_2}$\n",
    "3. Compute accuracy on ${\\mathcal D_2}$.\n",
    "4. Tweak algorithm / representation\n",
    "5. Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How do you know if it works?\n",
    "\n",
    "1. Train on data ${\\mathcal D_1}$\n",
    "2. Predict on data ${\\mathcal D_2}$\n",
    "3. Compute accuracy on ${\\mathcal D_2}$.\n",
    "4. Tweak algorithm / representation\n",
    "5. Repeat\n",
    "\n",
    "How many times can I do this?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Measuring Generalization\n",
    "\n",
    "- Cross-validation\n",
    "  - train on 90%, test on 10%, repeat 10 x's\n",
    "       - each example appears only once in test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Experimental Design\n",
    "\n",
    "1. Collect data\n",
    "2. Build model\n",
    "3. Compute cross-validation accuracy\n",
    "4. Tune model\n",
    "5. Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Experimental Design\n",
    "\n",
    "1. Collect data\n",
    "2. Build model\n",
    "3. Compute cross-validation accuracy\n",
    "4. Tune model\n",
    "5. Repeat\n",
    "6. **Report accuracy on new data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "- What is overfitting? How do you know it is happening? How do you fix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src='images/biasvariance.png' width='70%'/>\n",
    "\n",
    "<http://scott.fortmann-roe.com/docs/BiasVariance.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Machine Learning for Sentiment Analysis\n",
    "\n",
    "1. Collect data: E.g., <http://help.sentiment140.com/for-students>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Download Twitter data labeled by sentiment.\n",
    "\n",
    "from StringIO import StringIO\n",
    "from zipfile import ZipFile\n",
    "from urllib import urlopen\n",
    "\n",
    "# The file is 78M, so this will take a while.\n",
    "#url = urlopen('http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip')\n",
    "#zipfile = ZipFile(StringIO(url.read()))\n",
    "# We'll focus on the smaller file that was manually labeled.\n",
    "# The larger file has 1.6M tweets \"pseudo-labeled\" using emoticons\n",
    "tweet_file = zipfile.open('testdata.manual.2009.06.14.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 498 tweets\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "file_reader = csv.reader(tweet_file, delimiter=',', quotechar='\"')\n",
    "tweets = []\n",
    "for row in file_reader:\n",
    "    tweets.append({'label': int(row[0]),\n",
    "                   'text': row[5]})\n",
    "print 'read %d tweets' % len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 4,\n",
       " 'text': '@stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label counts= Counter({4: 182, 0: 177, 2: 139})\n"
     ]
    }
   ],
   "source": [
    "# Create label vector (y) and print its stats.\n",
    "from collections import Counter\n",
    "y = np.array([t['label'] for t in tweets])\n",
    "print 'label counts=', Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorized 498 tweets. found 2264 terms.\n"
     ]
    }
   ],
   "source": [
    "# Create feature vectors (X)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(t['text'] for t in tweets)\n",
    "print 'vectorized %d tweets. found %d terms.' % (X.shape[0], X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'msgs', 1325),\n",
       " (u'whoopi', 2176),\n",
       " (u'sleep', 1804),\n",
       " (u'6pm', 67),\n",
       " (u'hate', 920),\n",
       " (u'whose', 2177),\n",
       " (u'boortz', 317),\n",
       " (u'davehitt', 557),\n",
       " (u'bike', 276),\n",
       " (u'under', 2072)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print part of the vocabulary.\n",
    "vectorizer.vocabulary_.items()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_indices= [1961 1998  988 ..., 1363 1364    0]\n",
      "top_terms:\n",
      "the 1961\n",
      "to 1998\n",
      "http 988\n",
      "is 1060\n",
      "and 152\n",
      "at 209\n",
      "it 1062\n",
      "for 790\n",
      "my 1337\n",
      "of 1416\n"
     ]
    }
   ],
   "source": [
    "# What are the most frequent terms?\n",
    "# Sum columns:\n",
    "col_sums = X.sum(axis=0).tolist()[0]\n",
    "# Sort sums in descending order, and return the indices.\n",
    "top_indices = np.argsort(col_sums)[::-1]\n",
    "print 'top_indices=', top_indices\n",
    "vocab = np.array(vectorizer.get_feature_names())\n",
    "top_terms = vocab[top_indices]\n",
    "print 'top_terms:\\n', '\\n'.join('%s %d' % (term, count) for term, count in zip(top_terms, top_indices)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2.) Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a LogisticRegression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training data=0.996\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy\n",
    "def accuracy(truth, predicted):\n",
    "    return (1. * len([1 for tr, pr in zip(truth, predicted) if tr == pr]) / len(truth))\n",
    "\n",
    "predicted = model.predict(X)\n",
    "print 'accuracy on training data=%.3f' % accuracy(y, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top weighted terms for positive class:\n",
      "awesome 1.52\n",
      "love 1.51\n",
      "g2 1.23\n",
      "good 1.17\n",
      "kindle2 1.03\n",
      "lebron 0.95\n",
      "great 0.89\n",
      "mcdonalds 0.81\n",
      "tonight 0.80\n",
      "mashable 0.80\n"
     ]
    }
   ],
   "source": [
    "# What are the top weighted features?\n",
    "\n",
    "# Get the learned coefficients for the Positive class.\n",
    "coef = model.coef_[2]\n",
    "# Sort them in descending order.\n",
    "top_coef_ind = np.argsort(coef)[::-1]\n",
    "# Get the names of those features.\n",
    "top_coef_terms = vocab[top_coef_ind]\n",
    "# Get the weights of those features\n",
    "top_coef = coef[top_coef_ind]\n",
    "# Print the top 10.\n",
    "print 'top weighted terms for positive class:\\n', \\\n",
    "    '\\n'.join('%s %.2f' % (term, weight) for term, weight in zip(top_coef_terms, top_coef)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top weighted terms for negative class:\n",
      "warner 1.56\n",
      "hate 1.29\n",
      "aig 1.28\n",
      "gm 1.08\n",
      "korea 1.06\n",
      "north 1.06\n",
      "not 1.05\n",
      "cheney 0.94\n",
      "that 0.89\n",
      "fail 0.89\n"
     ]
    }
   ],
   "source": [
    "# Get the learned coefficients for the Negative class.\n",
    "coef = model.coef_[0]\n",
    "# Sort them in descending order.\n",
    "top_coef_ind = np.argsort(coef)[::-1]\n",
    "# Get the names of those features.\n",
    "top_coef_terms = vocab[top_coef_ind]\n",
    "# Get the weights of those features\n",
    "top_coef = coef[top_coef_ind]\n",
    "# Print the top 10.\n",
    "print 'top weighted terms for negative class:\\n', \\\n",
    "    '\\n'.join('%s %.2f' % (term, weight) for term, weight in zip(top_coef_terms, top_coef)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average 5-fold cross validation accuracy=0.67 (std=0.04)\n"
     ]
    }
   ],
   "source": [
    "# 5 Cross-validation accuracy\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "cv = KFold(len(y), 5)\n",
    "accuracies = []\n",
    "for train_ind, test_ind in cv:\n",
    "    model.fit(X[train_ind], y[train_ind])\n",
    "    predictions = model.predict(X[test_ind])\n",
    "    accuracies.append(accuracy(y[test_ind], predictions))\n",
    "    \n",
    "print 'Average 5-fold cross validation accuracy=%.2f (std=%.2f)' % (np.mean(accuracies), np.std(accuracies))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
